syntax = "proto3";

package proxy.v1;

option go_package = "lb/pb";

// -----------------------------------------
// User & Auth
// -----------------------------------------

message LoginRequest {
  string username = 1; // json: "username"
  string password = 2; // json: "password"
}

message LoginResponse {
  string user_id = 1;  // json: "user_id"
  string api_key = 2;  // json: "api_key"
  bool is_admin = 3;   // json: "is_admin"
}

// -----------------------------------------
// Admin
// -----------------------------------------

message SetLimitsRequest {
  string user_id = 1;
  int32 rps = 2;
  int64 max_tokens = 3;
  int64 max_tokens_per_request = 4;
}

message SetLimitsResponse {
  string user_id = 1;
  int32 rps = 2;
  int64 max_tokens = 3;
  int64 max_tokens_per_request = 4;
}

message SuspendUserRequest {
  string user_id = 1;
}

message SuspendUserResponse {
  string user_id = 1;
  string status = 2;
}

// Represents the LimitInfo struct returned by the limiter
message LimitInfo {
  int64 max_tokens = 1;         // Go json mapping: "MaxTokens"
  int64 max_tokens_per_req = 2; // Go json mapping: "MaxTokensPerReq"
  int64 used_tokens = 3;        // Go json mapping: "UsedTokens"
  double rps = 4;               // Go json mapping: "RPS"
}

// GET /admin/limits returns a map of UserID -> LimitInfo
message AllLimitsResponse {
  map<string, LimitInfo> limits = 1;
}

// -----------------------------------------
// Usage Tracking
// -----------------------------------------

// Represents the ModelUsage struct
message ModelUsage {
  int32 prompt_tokens = 1;
  int32 completion_tokens = 2;
}

// GET /v1/usage returns a map of ModelName -> ModelUsage
message UsageResponse {
  map<string, ModelUsage> usage_by_model = 1;
}

// GET /admin/usage returns a map of UserID -> (ModelName -> ModelUsage)
message AllUsageResponse {
  map<string, UsageResponse> usage_by_user = 1;
}

// -----------------------------------------
// Completions API (OpenAI Compatible)
// -----------------------------------------
// Note: Only the core fields handled by the proxy are defined here.

message ChatMessage {
  string role = 1;
  string content = 2;
  // Multimodal inputs (like base64 images) are technically supported via an array
  // of content parts in the OpenAI spec, but kept simple here for the string baseline.
}

message ChatCompletionRequest {
  string model = 1;
  repeated ChatMessage messages = 2;
  bool stream = 3;
  int32 max_tokens = 4;
}
